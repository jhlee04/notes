```
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

# classification_report â†’ ë”•ì…”ë„ˆë¦¬ ë³€í™˜
from sklearn.metrics import precision_recall_fscore_support

labels = ['on-track', 'at-risk']
zero_f1 = precision_recall_fscore_support(eval_df['ì •ë‹µ'], eval_df['zero-shot'], labels=labels, zero_division=0)[2]
s3_f1 = precision_recall_fscore_support(eval_df['ì •ë‹µ'], eval_df['status3'], labels=labels, zero_division=0)[2]

x = range(len(labels))  # 0: on-track, 1: at-risk
width = 0.35

plt.figure(figsize=(8, 5))
bars1 = plt.bar([i - width/2 for i in x], zero_f1, width=width, label='Zero-shot')
bars2 = plt.bar([i + width/2 for i in x], s3_f1, width=width, label='LLM status3')

# ìˆ˜ì¹˜ í‘œì‹œ
for bar in bars1 + bars2:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f"{height:.2f}", ha='center', va='bottom')

plt.xticks(x, labels)
plt.ylim(0, 1.05)
plt.ylabel("F1-score")
plt.title("ìƒíƒœë³„ F1-score ë¹„êµ (Zero-shot vs Status3)")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

```



ì•„ì£¼ ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤.
ì •í™•ë„ë¿ ì•„ë‹ˆë¼ F1-score í•´ì„ ê¸°ì¤€, ê·¸ë˜í”„ ìˆ˜ì¹˜ í‘œí˜„, í´ë˜ìŠ¤ë³„ ì •í™•ë„ ë¶„ì„ê¹Œì§€ ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ ëª¨ë‘ ë°˜ì˜í•´ ì•„ë˜ì— ì •ë¦¬í•´ë“œë¦´ê²Œìš”.


---

âœ… 1. F1-scoreëŠ” ì–¼ë§ˆë‚˜ ë†’ì•„ì•¼ â€œì¢‹ì€â€ ì„±ëŠ¥ì¸ê°€?

F1 Score ë²”ìœ„	í•´ì„

0.90 ~ 1.00	ë§¤ìš° ìš°ìˆ˜í•œ ëª¨ë¸ (ê±°ì˜ ì™„ë²½)
0.80 ~ 0.89	ì‹¤ë¬´ ì ìš©ì— ì¶©ë¶„íˆ ìš°ìˆ˜
0.70 ~ 0.79	ê°œì„  ì—¬ì§€ê°€ ìˆëŠ” ì‹¤ìš© ëª¨ë¸
0.60 ~ 0.69	ê¸°ì¤€ì„  ì •ë„ (Baseline ìˆ˜ì¤€)
< 0.60	ë¶ˆì•ˆì •í•œ ëª¨ë¸, ì¬êµ¬ì„± í•„ìš”


â†’ 0.8 ì´ìƒì´ë©´ ì‹¤ë¬´ ê¸°ì¤€ì—ì„œëŠ” â€œì‹ ë¢°í•  ìˆ˜ ìˆë‹¤â€ëŠ” ì¸ì‹ìœ¼ë¡œ ë´ë„ ì¢‹ìŠµë‹ˆë‹¤.
íŠ¹íˆ status íŒë‹¨ì²˜ëŸ¼ ëª¨í˜¸í•  ìˆ˜ ìˆëŠ” ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” 0.75~0.85ë„ ë§¤ìš° ì˜ë¯¸ ìˆìŠµë‹ˆë‹¤.


---

âœ… 2. on-trackê³¼ at-risk ê°ê°ì˜ ë¶„ë¥˜ ì •í™•ë„ (ì •ë°€ë„/ì¬í˜„ìœ¨)ë„ í‘œí˜„í•˜ê¸°

â†’ classification_report() ë˜ëŠ” í´ë˜ìŠ¤ë³„ precision, recall, f1-score ì¶œë ¥ìœ¼ë¡œ ê°€ëŠ¥


---

âœ… 3. ì •í™•ë„ & F1-score ì‹œê°í™” (ë§‰ëŒ€ê·¸ë˜í”„ + ìˆ˜ì¹˜ í‘œê¸°)
```
import matplotlib.pyplot as plt

# ì •í™•ë„ ë° F1 ì ìˆ˜
labels = ['Zero-shot', 'LLM status3']
accs = [acc_zero, acc_s3]
f1s = [f1_zero, f1_s3]

x = range(len(labels))
width = 0.35

plt.figure(figsize=(8, 5))
bars1 = plt.bar(x, accs, width=width, label='Accuracy')
bars2 = plt.bar([i + width for i in x], f1s, width=width, label='F1-score')

# ìˆ˜ì¹˜ í‘œì‹œ
for bar in bars1 + bars2:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.01, f"{height:.2f}", ha='center', va='bottom')

plt.xticks([i + width / 2 for i in x], labels)
plt.ylim(0, 1.05)
plt.ylabel("Score")
plt.title("LLM ìƒíƒœ ì˜ˆì¸¡ ì •í™•ë„ / F1-score ë¹„êµ")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

```
---

âœ… 4. on-track vs at-risk ê°ê°ì˜ ë¶„ë¥˜ ì„±ëŠ¥ ë³´ê¸°
```
from sklearn.metrics import classification_report

print("ğŸ” Zero-shot ëª¨ë¸ ì„±ëŠ¥:")
print(classification_report(eval_df['ì •ë‹µ'], eval_df['zero-shot'], target_names=['on-track', 'at-risk']))

print("\nğŸ” Status3 ëª¨ë¸ ì„±ëŠ¥:")
print(classification_report(eval_df['ì •ë‹µ'], eval_df['status3'], target_names=['on-track', 'at-risk']))
```
ì´ë ‡ê²Œ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í…ìŠ¤íŠ¸ ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤:

precision    recall  f1-score   support

   on-track       0.87      0.91      0.89        45
    at-risk       0.83      0.76      0.79        34

    accuracy                           0.85        79


---

âœ… ê²°ë¡  ì •ë¦¬

í•­ëª©	ê¶Œì¥ ì—¬ë¶€	ì´ìœ 

Accuracyë§Œ ë³´ëŠ” ê²ƒ	âŒ ë¶€ì¡±	ë¶ˆê· í˜•ì¼ ê²½ìš° ì™œê³¡ ê°€ëŠ¥ì„±
F1-score í¬í•¨	âœ… í•„ìˆ˜	ì „ì²´ ê· í˜• íŒë‹¨ ê°€ëŠ¥
on-track / at-risk ë³„ ì„±ëŠ¥ ë¶„ë¦¬	âœ… ë§¤ìš° ê¶Œì¥	ì–´ë–¤ ìƒíƒœì—ì„œ ì˜¤ë¶„ë¥˜ê°€ ë§ì€ì§€ ì§„ë‹¨ ê°€ëŠ¥
ìˆ˜ì¹˜ ì‹œê°í™” í‘œì‹œ	âœ… ì¶”ì²œ	ë¦¬ë”Â·ì‚¬ìš©ìì—ê²Œ ì§ê´€ì  ì „ë‹¬ ê°€ëŠ¥



---
 
